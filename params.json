{"name":"Fselector","body":"FSelector: a Ruby gem for feature selection and ranking\r\n===========================================================\r\n\r\n**Home** [https://rubygems.org/gems/fselector](https://rubygems.org/gems/fselector)  \r\n**Source Code**: [https://github.com/need47/fselector](https://github.com/need47/fselector)  \r\n**Documentation** [http://rubydoc.info/gems/fselector/frames](http://rubydoc.info/gems/fselector/frames)  \r\n**Author**: Tiejun Cheng  \r\n**Email**: [need47@gmail.com](mailto:need47@gmail.com)  \r\n**Copyright**: 2012  \r\n**License**: MIT License  \r\n**Latest Version**: 0.8.1  \r\n**Release Date**: April 23 2012\r\n\r\nSynopsis\r\n--------\r\n\r\nFSelector is a Ruby gem that aims to integrate various feature \r\nselection/ranking algorithms and related functions into one single \r\npackage. Welcome to contact me (need47@gmail.com) if you'd like to \r\ncontribute your own algorithms or report a bug. FSelector allows user \r\nto perform feature selection by using either a single algorithm or an \r\nensemble of multiple algorithms, and other common tasks including \r\nnormalization and discretization on continuous data, as well as replace \r\nmissing feature values with certain criterion. FSelector acts on a \r\nfull-feature data set in either CSV, LibSVM or WEKA file format and \r\noutputs a reduced data set with only selected subset of features, which \r\ncan later be used as the input for various machine learning softwares \r\nsuch as LibSVM and WEKA. FSelector, as a collection of filter methods, \r\ndoes not implement any classifier like support vector machines or \r\nrandom forest. See below for a list of FSelector's features and \r\n{file:ChangeLog} for updates.\r\n\r\nFeature List\r\n------------\r\n\r\n**1. supported input/output file types**\r\n\r\n - csv\r\n - libsvm\r\n - weka ARFF\r\n - random data (for test purpose)\r\n\r\n**2. available feature selection/ranking algorithms**\r\n    \r\n    algorithm                         alias       feature_type  applicability\r\n    --------------------------------------------------------------------------------------\r\n    Accuracy                          Acc         discrete\r\n    AccuracyBalanced                  Acc2        discrete\r\n    BiNormalSeparation                BNS         discrete\r\n    CFS_d                             CFS_d       discrete\r\n    ChiSquaredTest                    CHI         discrete\r\n    CorrelationCoefficient            CC          discrete\r\n    DocumentFrequency                 DF          discrete\r\n    F1Measure                         F1          discrete\r\n    FishersExactTest                  FET         discrete\r\n    FastCorrelationBasedFilter        FCBF        discrete\r\n    GiniIndex                         GI          discrete\r\n    GMean                             GM          discrete\r\n    GSSCoefficient                    GSS         discrete\r\n    InformationGain                   IG          discrete\r\n    MatthewsCorrelationCoefficient    MCC, PHI    discrete\r\n    McNemarsTest                      MNT         discrete\r\n    OddsRatio                         OR          discrete\r\n    OddsRatioNumerator                ORN         discrete\r\n    PhiCoefficient                    Phi         discrete\r\n    Power                             Power       discrete\r\n    Precision                         Precision   discrete\r\n    ProbabilityRatio                  PR          discrete\r\n    Random                            Random      discrete\r\n    Recall                            Recall      discrete\r\n    Relief_d                          Relief_d    discrete      two-class, no missing data\r\n    ReliefF_d                         ReliefF_d   discrete\r\n    Sensitivity                       SN, Recall  discrete\r\n    Specificity                       SP          discrete\r\n    SymmetricalUncertainty            SU          discrete\r\n    BetweenWithinClassesSumOfSquare   BSS_WSS     continuous\r\n    CFS_c                             CFS_c       continuous\r\n    FTest                             FT          continuous\r\n    PMetric                           PM          continuous    two-class\r\n    Relief_c                          Relief_c    continuous    two-class, no missing data\r\n    ReliefF_c                         ReliefF_c   continuous\r\n    TScore                            TS          continuous    two-class\r\n    WilcoxonRankSum                   WRS         continuous    two-class\r\n    \r\n  **note for feature selection interace:**   \r\n    - for the algorithms of CFS\\_d, FCBF and CFS\\_c, use select\\_feature!  \r\n    - for other algorithms, use either select\\_feature\\_by\\_rank! or select\\_feature\\_by\\_score!\r\n\r\n**3. feature selection approaches**\r\n\r\n - by a single algorithm\r\n - by multiple algorithms in a tandem manner\r\n - by multiple algorithms in a consensus manner\r\n \r\n**4. availabe normalization and discretization algorithms for continuous feature**\r\n    \r\n    algorithm                         note\r\n    -------------------------------------------------------------------------------\r\n    normalize_by_log!                 normalize by logarithmic transformation\r\n    normalize_by_min_max!             normalize by scaling into [min, max]\r\n    normalize_by_zscore!              normalize by converting into zscore\r\n    discretize_by_equal_width!        discretize by equal width among intervals\r\n    discretize_by_equal_frequency!    discretize by equal frequency among intervals\r\n    discretize_by_ChiMerge!           discretize by ChiMerge algorithm\r\n    discretize_by_Chi2!               discretize by Chi2 algorithm\r\n    discretize_by_MID!                discretize by Multi-Interval Discretization\r\n    \r\n**5. availabe algorithms for replacing missing feature values**\r\n    \r\n    algorithm                         note                                feature_type                     \r\n    -------------------------------------------------------------------------------------------\r\n    replace_by_fixed_value!           replace by a fixed value            discrete, continuous\r\n    replace_by_mean_value!            replace by mean feature value       continuous\r\n    replace_by_most_seen_value!       replace by most seen feature value  discrete\r\n\r\nInstalling\r\n----------\r\n\r\nTo install FSelector, use the following command:\r\n\r\n    $ gem install fselector\r\n    \r\n  **note:** Start from version 0.5.0, FSelector uses the RinRuby gem (http://rinruby.ddahl.org) \r\n  as a seemless bridge to access the statistical routines in the R package (http://www.r-project.org), \r\n  which will greatly expand the inclusion of algorithms to FSelector, especially for those relying \r\n  on statistical test. To this end, please pre-install the R package. RinRuby should have been \r\n  auto-installed with FSelector via the above command.\r\n  \r\nUsage\r\n-----\r\n\r\n**1. feature selection by a single algorithm**\r\n\r\n    require 'fselector'\r\n\t\r\n    # use InformationGain as a feature ranking algorithm\r\n    r1 = FSelector::InformationGain.new\r\n    \r\n    # read from random data (or csv, libsvm, weka ARFF file)\r\n    # no. of samples: 100\r\n    # no. of classes: 2\r\n    # no. of features: 15\r\n    # no. of possible values for each feature: 3\r\n    # allow missing values: true\r\n    r1.data_from_random(100, 2, 15, 3, true)\r\n    \r\n    # number of features before feature selection\r\n    puts \"# features (before): \"+ r1.get_features.size.to_s\r\n    \r\n    # select the top-ranked features with scores >0.01\r\n    r1.select_feature_by_score!('>0.01')\r\n    \r\n    # number of features after feature selection\r\n    puts \"# features (after): \"+ r1.get_features.size.to_s\r\n    \r\n    # you can also use multiple alogirithms in a tandem manner\r\n    # e.g. use the ChiSquaredTest with Yates' continuity correction\r\n    # initialize from r1's data\r\n    r2 = FSelector::ChiSquaredTest.new(:yates_continuity_correction, r1.get_data)\r\n    \r\n    # number of features before feature selection\r\n    puts \"# features (before): \"+ r2.get_features.size.to_s\r\n    \r\n    # select the top-ranked 3 features\r\n    r2.select_feature_by_rank!('<=3')\r\n    \r\n    # number of features after feature selection\r\n    puts \"# features (after): \"+ r2.get_features.size.to_s\r\n    \r\n    # save data to standard ouput as a weka ARFF file (sparse format)\r\n    # with selected features only\r\n    r2.data_to_weka(:stdout, :sparse)\r\n\r\n\t\r\n**2. feature selection by an ensemble of multiple algorithms**\r\n\r\n    require 'fselector'\r\n\t\r\n\t# use both Information and ChiSquaredTest\r\n    r1 = FSelector::InformationGain.new\r\n    r2 = FSelector::ChiSquaredTest.new\r\n    \r\n    # ensemble ranker\r\n    re = FSelector::Ensemble.new(r1, r2)\r\n    \r\n    # read random data\r\n    re.data_from_random(100, 2, 15, 3, true)\r\n    \r\n    # number of features before feature selection\r\n    puts '# features (before): ' + re.get_features.size.to_s\r\n    \r\n    # based on the min feature rank among\r\n    # ensemble feature selection algorithms\r\n    re.ensemble_by_rank(re.method(:by_min))\r\n    \r\n    # select the top-ranked 3 features\r\n    re.select_feature_by_rank!('<=3')\r\n    \r\n    # number of features after feature selection\r\n    puts '# features (after): ' + re.get_features.size.to_s\r\n\r\n    \r\n**3. normalization and discretization before feature selection**\r\n\r\n In addition to the algorithms designed for continuous feature, one\r\n can apply those deisgned for discrete feature after (optionally\r\n normalization and) discretization\r\n \r\n    require 'fselector'\r\n    \r\n    # for continuous feature\r\n    r1 = FSelector::Relief_c.new\r\n    \r\n    # read the Iris data set (under the test/ directory)\r\n    r1.data_from_csv('test/iris.csv')\r\n        \r\n    # discretization by ChiMerge algorithm at alpha=0.10\r\n    r1.discretize_by_ChiMerge!(0.10)\r\n    \r\n    # apply Fast Correlation-Based Filter (FCBF) algorithm for discrete feature\r\n    # initialize with discretized data from r1\r\n    r2 = FSelector::FCBF.new(0.0, r1.get_data)\r\n    \r\n    # number of features before feature selection\r\n    puts '# features (before): ' + r2.get_features.size.to_s\r\n    \r\n    # feature selection\r\n    r2.select_feature!\r\n    \r\n    # number of features after feature selection\r\n    puts '# features (after): ' + r2.get_features.size.to_s\r\n\r\n**4. see more examples test_*.rb under the test/ directory**\r\n\r\nChange Log\r\n----------\r\nA {file:ChangeLog} is available from version 0.5.0 and upward to refelect \r\nwhat's new and what's changed \r\n\r\nCopyright\r\n---------\r\nFSelector &copy; 2012 by [Tiejun Cheng](mailto:need47@gmail.com).\r\nFSelector is licensed under the MIT license. Please see the {file:LICENSE} for\r\nmore information.\r\n","tagline":"a Ruby gem for feature selection and ranking","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}